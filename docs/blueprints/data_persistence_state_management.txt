# Data Persistence and State Management
# Distributed state synchronization with high-availability architecture

persistence_metadata:
  name: "TadpoleStatePersistence"
  version: "3.5.0"
  consistency_model: "eventual_consistency_with_strong_convergence"
  durability_guarantee: "crash_recovery_capable"

# State Architecture and Data Models
state_architecture:
  hierarchical_state_model:
    system_state:
      scope: "global_system_configuration"
      consistency_requirement: "strong_consistency"
      replication_factor: 3
      persistence_layer: "distributed_consensus_log"
      
    population_state:
      scope: "agent_population_metadata"
      consistency_requirement: "eventual_consistency"
      replication_factor: 2
      persistence_layer: "replicated_state_machine"
      subspaces:
        judgement_snapshots:
          schema: "tadpole_metadata_judgement_system.txt#judgement_ledger"
          retention_policy: "90_days_detailed_1_year_summary"
        egg_revision_history:
          schema: "tadpole_metadata_judgement_system.txt#egg_revision_workflow"
          retention_policy: "permanent_with_archival"
        job_resource_ledger:
          schema: "task_orchestration_system.txt#resource_pools"
          retention_policy: "180_days_detailed_2_years_summary"
        job_event_log:
          schema: "task_orchestration_system.txt#job_lifecycle"
          retention_policy: "365_days_detailed"
        worker_journal:
          schema: "worker_orchestration_system.txt#meta_feedback"
          retention_policy: "365_days_detailed_3_years_archive"
        tadpole_activity_log:
          schema: "tadpole_metadata_judgement_system.txt#metadata_pipeline"
          retention_policy: "90_days_detailed"
      
    agent_state:
      scope: "individual_agent_data"
      consistency_requirement: "causal_consistency"
      replication_factor: 1  # with backup
      persistence_layer: "agent_local_storage_with_sync"
      
    mesh_state:
      scope: "network_topology_and_relationships"
      consistency_requirement: "eventual_consistency"
      replication_factor: 2
      persistence_layer: "graph_database_distributed"

  data_models:
    agent_data_model:
      identity:
        agent_id: "uuid4_primary_key"
        public_key: "ed25519_verification_key"
        generation: "integer_genealogy_tracking"
        creation_timestamp: "unix_nanosecond_precision"
        
      performance_state:
        current_metrics: "time_series_current_window"
        historical_metrics: "compressed_time_series"
        rubric_scores: "multidimensional_performance_vector"
        judgement_snapshot_ref: "population_state.judgement_snapshots"
        job_allocation_ref: "population_state.job_resource_ledger"
        
      knowledge_state:
        learned_patterns: "neural_network_weights_serialized"
        experience_history: "event_log_compressed"
        capability_vector: "float32_array_256_dimensions"
        
      relationship_state:
        mesh_memberships: "graph_adjacency_list"
        communication_history: "interaction_log_summarized"
        trust_scores: "peer_reputation_matrix"
    
    mesh_data_model:
      topology:
        mesh_id: "uuid4_mesh_identifier"
        member_agents: "agent_id_array"
        formation_timestamp: "unix_nanosecond_precision"
        topology_hash: "merkle_tree_root_hash"
        
      performance_data:
        collective_metrics: "aggregated_mesh_performance"
        emergence_indicators: "synergy_measurement_vectors"
        communication_efficiency: "bandwidth_utilization_metrics"
        
      capability_fusion:
        fused_capabilities: "merged_capability_vectors"
        fusion_history: "capability_evolution_log"
        synergy_matrix: "interaction_effect_measurements"

postgres_relational_layer:
  description: "Structured ledger hosted on PostgreSQL for long-lived analytics and Custom GPT alignment."
  connection_profile:
    env_variable: "ADAPTIVE_DATABASE_URL"
    migration_strategy: "sqlalchemy_metadata_autocreate_with_reviewed_alter_statements"
    dynamic_extension: "schema_change_log_controls_column_growth"
  orchestration_tables:
    jobs:
      schema_anchor: "postgres_relational_layer.jobs"
      primary_key: "job_id"
      columns:
        - "objective TEXT"
        - "status VARCHAR(32)"
        - "reward_signal FLOAT"
        - "requested_resources JSONB"
        - "metadata JSONB"
        - "spawned_at TIMESTAMPTZ"
        - "started_at TIMESTAMPTZ"
        - "completed_at TIMESTAMPTZ"
      notes: "Every `/assign_job` invocation upserts here; resource allocations referenced via resource_allocations.job_id."
    job_metrics:
      primary_key: "id SERIAL"
      foreign_keys:
        - "job_id -> jobs.job_id"
      purpose: "time-series metrics recorded on job completion (latency, efficiency, ttl expirations)."
    resource_allocations:
      foreign_keys:
        - "job_id -> jobs.job_id"
      columns:
        - "compute_units INT"
        - "memory_mb INT"
        - "bandwidth_mbps INT"
        - "thread_count INT"
        - "allocated_at TIMESTAMPTZ"
        - "released_at TIMESTAMPTZ NULLABLE"
      notes: "Supports capacity replay and throttling recommendations."
    workers:
      primary_key: "worker_id"
      columns:
        - "job_id VARCHAR NULL"
        - "worker_type VARCHAR(32)"  # tadpole | quest_worker | supervisor
        - "specialization VARCHAR"
        - "status VARCHAR(32)"
        - "spawned_at TIMESTAMPTZ"
        - "retired_at TIMESTAMPTZ"
        - "ttl_seconds INT"
        - "expiry_at TIMESTAMPTZ"
        - "metadata JSONB"
      notes: "Captures both tadpoles and higher-order workers; lifecycle events fan out via worker_events."
    worker_events:
      foreign_keys:
        - "worker_id -> workers.worker_id"
      columns:
        - "event_type VARCHAR(64)"
        - "payload JSONB"
        - "occurred_at TIMESTAMPTZ"
    tadpole_instances:
      primary_key: "tadpole_id"
      foreign_keys:
        - "worker_id -> workers.worker_id"
        - "job_id -> jobs.job_id"
      columns:
        - "communication_protocol VARCHAR"
        - "resource_allocation JSONB"
        - "status VARCHAR(32)"
        - "spawned_at TIMESTAMPTZ"
        - "expiry_at TIMESTAMPTZ"
      notes: "Allows TTL analysis and per-tadpole outcome tracing."
    tadpole_metrics:
      foreign_keys:
        - "tadpole_id -> tadpole_instances.tadpole_id"
      purpose: "micro-metrics for each tadpole (entropy, resource pressure, protocol success)."
    dynamic_attributes:
      columns:
        - "entity_type VARCHAR(32)"
        - "entity_id VARCHAR(128)"
        - "attribute_key VARCHAR(128)"
        - "attribute_value JSONB"
        - "weight_hint FLOAT"
        - "observed_at TIMESTAMPTZ"
      notes: "Main engine stores experimental fields here before materialising schema changes."
    schema_change_log:
      columns:
        - "initiated_by VARCHAR(128)"
        - "entity_name VARCHAR(128)"
        - "action VARCHAR(64)"  # proposed | applied
        - "ddl_statement TEXT"
        - "rationale TEXT"
        - "created_at TIMESTAMPTZ"
      notes: "Operations review uses this ledger to approve dynamic column additions."
    code_versions:
      purpose: "Digest-indexed catalogue of worker code artifacts."
    code_update_reports:
      purpose: "Worker-authored improvement suggestions referencing code_versions."
      policy: "No automatic deployment; reports feed manual review."
    analysis_requests:
      purpose: "Stores trial prompts such as monetization scans or Cardano forecasting missions."
      lifecycle: "queued -> running -> completed"
    analysis_runs:
      notes: "Joins trial requests to concrete jobs/workers and summarises outcomes."
    analysis_findings:
      purpose: "Structured outputs for reviewers (monetization_score, novelty_score)."
    finding_artifacts:
      purpose: "URI pointers to notebooks, charts, or raw data supporting findings."
    improvement_reports:
      purpose: "Tracks job- or request-linked adjustment bundles for governance."
    learning_snapshots:
      purpose: "Chronicles principle scores persisted alongside rubric version for longitudinal review."

# Storage Backend Configuration
storage_backends:
  primary_storage:
    distributed_database:
      engine: "etcd_cluster"  # for system state
      cluster_size: 3
      persistence_backend: "raft_consensus_log"
      data_encryption: "aes_256_gcm_at_rest"
      
    time_series_database:
      engine: "prometheus_with_thanos"  # for metrics
      retention_policy: "30d_raw_1y_downsampled"
      compression_algorithm: "snappy_compression"
      query_optimization: "index_based_acceleration"
      
    graph_database:
      engine: "dgraph_distributed"  # for relationships
      schema_evolution: "backward_compatible"
      query_language: "graphql_with_dql"
      sharding_strategy: "hash_based_partitioning"
      
  caching_layer:
    memory_cache:
      engine: "redis_cluster"
      cache_size: "25_percent_available_memory"
      eviction_policy: "lru_with_ttl"
      persistence_mode: "rdb_aof_hybrid"
      
    distributed_cache:
      engine: "hazelcast_embedded"
      near_cache_enabled: true
      cache_coherence: "eventual_consistency"
      partition_tolerance: "ap_cap_theorem_choice"

  backup_storage:
    incremental_backups:
      frequency: "hourly"
      retention_schedule: "24h_hourly_30d_daily_1y_weekly"
      compression: "zstd_level_3"
      encryption: "age_encryption_with_recipients"
      
    snapshot_storage:
      full_system_snapshots: "daily"
      snapshot_verification: "integrity_checksum_validation"
      cross_site_replication: "optional_for_disaster_recovery"

# State Synchronization Mechanisms
state_synchronization:
  consensus_protocols:
    raft_consensus:
      use_cases: ["system_configuration", "critical_decisions"]
      election_timeout: "150_to_300_milliseconds"
      heartbeat_interval: "50_milliseconds"
      log_compaction: "automatic_when_threshold_reached"
      
    gossip_protocol:
      use_cases: ["mesh_state_propagation", "performance_metrics"]
      gossip_interval: "100_milliseconds"
      gossip_fanout: 3
      anti_entropy_mechanism: "merkle_tree_synchronization"
      
    vector_clocks:
      use_cases: ["causal_consistency_tracking", "conflict_resolution"]
      clock_synchronization: "ntp_disciplined_local_clocks"
      conflict_resolution: "last_writer_wins_with_tie_breaking"

  conflict_resolution:
    multi_version_concurrency_control:
      version_tracking: "vector_timestamps"
      conflict_detection: "read_write_dependency_analysis"
      resolution_strategy: "application_specific_merge_functions"
      
    operational_transformation:
      use_cases: ["collaborative_capability_editing"]
      transformation_functions: "commutative_transformation_rules"
      state_convergence: "eventual_consistency_guarantee"
      
    crdt_data_structures:
      supported_types:
        - "g_counter"  # grow-only counter
        - "pn_counter" # increment/decrement counter  
        - "g_set"      # grow-only set
        - "or_set"     # observed-remove set
      use_cases: ["distributed_metrics", "capability_sets"]

# Transaction Management
transaction_system:
  acid_properties:
    atomicity: "two_phase_commit_for_distributed_transactions"
    consistency: "application_level_invariant_checking"
    isolation: "snapshot_isolation_default"
    durability: "write_ahead_logging_with_fsync"
    
  distributed_transactions:
    coordination_protocol: "saga_pattern"
    compensation_actions: "automatic_rollback_procedures"
    timeout_handling: "progressive_timeout_with_circuit_breaker"
    
    transaction_types:
      agent_spawning_transaction:
        steps: ["resource_allocation", "state_initialization", "registration"]
        compensation: ["resource_deallocation", "state_cleanup", "deregistration"]
        
      mesh_formation_transaction:
        steps: ["capability_negotiation", "topology_update", "state_sync"]
        compensation: ["capability_rollback", "topology_revert", "state_cleanup"]
        
      performance_update_transaction:
        steps: ["metric_validation", "state_update", "propagation"]
        compensation: ["metric_rollback", "state_revert", "correction_broadcast"]

# Data Migration and Schema Evolution
schema_management:
  versioning_strategy:
    semantic_versioning: "major_minor_patch_format"
    backward_compatibility: "n_minus_2_versions_supported"
    migration_automation: "zero_downtime_deployment"
    
  migration_procedures:
    online_schema_evolution:
      dual_write_phase: "write_both_old_and_new_schema"
      gradual_migration: "background_data_transformation"
      validation_phase: "consistency_checking_between_schemas"
      cutover_phase: "atomic_traffic_switch"
      
    data_transformation:
      transformation_rules: "declarative_transformation_specifications"
      validation_functions: "data_integrity_verification"
      rollback_procedures: "automatic_rollback_on_validation_failure"

# Performance Optimization
performance_tuning:
  read_optimization:
    query_optimization:
      index_strategy: "composite_indexes_for_common_queries"
      query_planning: "cost_based_optimizer"
      materialized_views: "precomputed_aggregations"
      
    caching_strategy:
      read_through_cache: "automatic_cache_population"
      cache_aside_pattern: "application_controlled_caching"
      write_behind_cache: "asynchronous_persistence"
      
  write_optimization:
    batch_processing:
      write_batching: "group_related_writes"
      batch_size_optimization: "dynamic_based_on_throughput"
      batch_timeout: "latency_bounded_batching"
      
    asynchronous_processing:
      write_ahead_logging: "immediate_ack_deferred_processing"
      background_compaction: "storage_optimization_processes"
      async_replication: "eventual_consistency_for_replicas"
      
  storage_optimization:
    compression_strategies:
      time_series_compression: "delta_compression_with_snappy"
      blob_compression: "zstd_for_large_objects"
      index_compression: "prefix_compression_for_btrees"
      
    partitioning_strategies:
      time_based_partitioning: "automatic_partition_creation"
      hash_based_partitioning: "even_distribution_across_nodes"
      range_based_partitioning: "query_optimization_friendly"

# Monitoring and Observability
storage_monitoring:
  performance_metrics:
    throughput_metrics:
      reads_per_second: 0
      writes_per_second: 0
      transactions_per_second: 0
      
    latency_metrics:
      read_latency_p95: 0  # milliseconds
      write_latency_p95: 0  # milliseconds
      transaction_latency_p99: 0  # milliseconds
      
    resource_utilization:
      storage_space_used: 0  # bytes
      memory_usage: 0  # bytes
      cpu_utilization: 0.0  # percentage
      network_bandwidth: 0  # bytes_per_second
      
  health_monitoring:
    consistency_monitoring:
      replica_lag_tracking: "real_time_replication_delay_measurement"
      consistency_violation_detection: "automated_invariant_checking"
      
    availability_monitoring:
      node_health_checking: "heartbeat_based_failure_detection"
      partition_tolerance_testing: "chaos_engineering_integration"
      
    integrity_monitoring:
      data_corruption_detection: "checksum_verification_background"
      backup_verification: "periodic_restore_testing"

# Disaster Recovery and High Availability
disaster_recovery:
  high_availability_configuration:
    replication_topology: "master_slave_with_automatic_failover"
    failover_time_objective: "30_seconds_maximum"
    data_loss_tolerance: "zero_data_loss_for_committed_transactions"
    
  backup_and_recovery:
    point_in_time_recovery:
      recovery_granularity: "transaction_level_precision"
      recovery_time_objective: "5_minutes_maximum"
      recovery_testing: "monthly_disaster_recovery_drills"
      
    cross_datacenter_replication:
      replication_strategy: "asynchronous_with_conflict_resolution"
      network_partition_handling: "split_brain_prevention"
      geographic_distribution: "multi_region_support"

# Integration APIs
persistence_apis:
  state_management_api:
    endpoints:
      - path: "/state/agent/{agent_id}"
        methods: ["GET", "PUT", "PATCH"]
        description: "individual_agent_state_management"
        
      - path: "/state/mesh/{mesh_id}" 
        methods: ["GET", "PUT", "DELETE"]
        description: "mesh_state_lifecycle_management"
        
      - path: "/state/system"
        methods: ["GET", "PATCH"]
        description: "system_wide_configuration_management"
        
  query_api:
    graphql_endpoint: "/graphql"
    rest_api_fallback: "/api/v1/query"
    query_optimization: "automatic_query_planning"
    
  streaming_api:
    state_change_streams: "server_sent_events"
    real_time_subscriptions: "websocket_based"
    event_sourcing_support: "append_only_event_log"
